{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coarse acquisition\n",
    "\n",
    "To aquire a GPS signal, we do a 2 dimensional search across the doppler frequency and L1C code phase. L1C is used since its code length is shortest (as opposed to L2C, which, while at the same rate of ~1MHz, lasts 20ms instead of 1ms).\n",
    "\n",
    "We import our test data from the file `data/g072602f.dat`, which file of binary bytes. The data is from 7/26/2002 at 13:56 EST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from gnss.codes import gps_l1\n",
    "from gnss.signals import Signal\n",
    "from gnss.receiver import sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We happen to know that the data in '../data/g072602f.dat' are real samples at 5 MHz of bit depth 8, and that the front-end center frequency was 1.25 MHz. The data contains GPS L1CA signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 1.048576 seconds of data\n"
     ]
    }
   ],
   "source": [
    "f_center = 1.25e6\n",
    "f_samp = 5e6\n",
    "filepath = '../../data/g072602f.dat'\n",
    "source = sources.FileSignalSource(filepath, f_samp=f_samp, f_center=f_center)\n",
    "source.load()\n",
    "print('we have {0} seconds of data'.format(source.buffer_size / source.f_samp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coarse aquisition is a 2 dimensional search. To perform coarse aquisition, we loop over each doppler bin frequency and search search for a correlation match between our signal $x(n)$ and our reference signal $x_{ref}(n)$. We can follow one of two procedures inside the loop over doppler bin frequencies:\n",
    "\n",
    "1. * wipe off excess doppler\n",
    "   * correlate with reference signal (which just includes samples of our code) at each code phase\n",
    "2. * correlate with reference signal that includes code samples multiplied by complex exponential at our doppler frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods are equivalent (I tested it). To show why, consider the correlation between $x(n)$ and $x_{ref}(n)$:\n",
    "\n",
    "$x \\star x_{ref}(n) = \\sum_{k=<N>} x(k)x^*_{ref}(k+n)$\n",
    "\n",
    "where $x^*_{ref}$ is the complex conjugate of $x_{ref}$.\n",
    "\n",
    "If we were performing the second method, where our reference contains the doppler, then we have (ignoring nav data, amplitude and noise of our signal):\n",
    "\n",
    "$x(n) = C(n + n_0)e^{j(2\\pi \\frac{f_d}{f_s}n + \\phi_0)} \\\\\n",
    "x^*_{ref}(n) = C(n)e^{-j2\\pi \\frac{\\hat{f_d}}{f_s}n} \\\\\n",
    "x \\star x_{ref}(n) = \\sum_{k=<N>} C(k+n_0)e^{j(2\\pi \\frac{f_d}{f_s}k + \\phi_0)} C(k+n)e^{-j2\\pi \\frac{\\hat{f_d}}{f_s}(k+n)} \\\\\n",
    "= \\sum_{k=<N>} C(k+n_0)C(k+n)e^{j\\phi_0} e^{-j2\\pi \\frac{\\hat{f_d}}{f_s}n} \\\\\n",
    "= e^{j(\\phi_0 - 2\\pi\\frac{\\hat{f_d}}{f_s}n)} \\sum_{k=<N>} C(k+n_0)C(k+n)e^{j2\\pi \\frac{\\Delta f_d}{f_s}k}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the correlation process wipes off the excess doppler anyway. When our doppler bin frequency is a match, $\\Delta f_d \\approx 0$ and the summation becomes the correlation between the codes. The only remaining trace of our doppler bin frequency is a complex exponential outfront--$e^{j(\\phi_0 - 2\\pi\\frac{\\hat{f_d}}{f_s}n)}$--whose magnitude is $1$.\n",
    "\n",
    "We use two types of integration to improve our signal-to-noise ratio when acquiring: **coherent** and **non-coherent**.\n",
    "\n",
    "The level of coherent integration depends on our block length--doubling block length should increase SNR by 3dB. Non-coherent integration depends on the number of blocks for which we stack correlation results. As a preliminary step in performing coarse aquisition, we divide our signal into `num_blocks` blocks of duration `block_length` each, and take the FFT of each block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "block_length = 2e-3\n",
    "num_blocks = 5\n",
    "num_block_samples = round(block_length * source.f_samp)\n",
    "num_samples = num_blocks * num_block_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a set of doppler frequency bins with spacing less than or equal to one over our block length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dopp_bins = np.arange(-5000., 5000., 1. / block_length)  # in Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an array to store our correlation results over our doppler frequency and code phase bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr = np.zeros((len(dopp_bins), num_block_samples), dtype=np.complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can only perform aquisition for one PRN at a time, so we choose PRN 21, which we know to be present in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svid = 21\n",
    "signal = Signal.GPSL1CA(svid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, for each doppler bin frequency, we:\n",
    "- generate our reference signal\n",
    "- take the conjugate of the FFT\n",
    "- multiply it by the FFT of our signal blocks\n",
    "- take the IFFT\n",
    "- sum the blocks to get correlation for the relevant doppler frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fft_blocks = np.fft.fft(source.block(num_samples).reshape((num_blocks, num_block_samples)), axis=1)\n",
    "\n",
    "t = np.arange(num_block_samples) / source.f_samp\n",
    "indices = (np.floor(t * signal.code.rate) % len(signal.code.sequence)).astype(int)\n",
    "code_samples = 1. - 2. * signal.code.sequence[indices]\n",
    "\n",
    "for i, f_dopp in enumerate(dopp_bins):\n",
    "    reference = code_samples * np.exp(2j * np.pi * (source.f_center + f_dopp) * t)\n",
    "    fft_conjugate = np.conj(np.fft.fft(reference))\n",
    "    corr[i, :] = np.sum(np.fft.ifft(fft_conjugate * fft_blocks), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we find the peak value of the correlation magnitude (`np.abs(corr)`). Numpy's `unravel_index` utility makes it easy to find peak indices over two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max at 2000.0 Hz and 841 code phase offset with SNR: 13.61654110757823\n"
     ]
    }
   ],
   "source": [
    "abs_corr = np.absolute(corr[:,:5000])\n",
    "f_dopp_i, n0 = np.unravel_index(abs_corr.argmax(), abs_corr.shape)\n",
    "max_val = abs_corr[f_dopp_i, n0]\n",
    "snr = max_val / ((np.sum(abs_corr) - max_val) / (abs_corr.size - 1))\n",
    "print('max at {0} Hz and {1} code phase offset with SNR: {2}'.format(dopp_bins[f_dopp_i], n0, snr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1, projection='3d')\n",
    "x, y = np.meshgrid(np.arange(1, abs_corr.shape[1]+1), dopp_bins)\n",
    "surf = ax.plot_surface(x, y, abs_corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../gnss/acquisition/coarse.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../gnss/acquisition/coarse.py\n",
    "\n",
    "\n",
    "import numpy\n",
    "\n",
    "class CoarseAcquirer:\n",
    "    \n",
    "    def __init__(self, source, block_length, num_blocks, dopp_bins=None, dopp_min=-5000, dopp_max=5000):\n",
    "        self.block_length = block_length\n",
    "        self.num_blocks = num_blocks   \n",
    "        if not dopp_bins:\n",
    "            self.dopp_bins = numpy.arange(dopp_min, dopp_max, 1. / block_length)\n",
    "        else:\n",
    "            self.dopp_bins = dopp_bins\n",
    "        self.source = source\n",
    "        self.num_block_samples = self.block_length * source.f_samp\n",
    "        self.num_samples = self.num_blocks * self.num_block_samples\n",
    "        self.correlation = numpy.zeros((len(self.dopp_bins), self.num_block_samples), dtype=numpy.complex)\n",
    "        self.t = numpy.arange(self.num_block_samples) / source.f_samp\n",
    "        \n",
    "    def acquire(self, signal, time=None):\n",
    "        # correlate\n",
    "        self.time_of_acquisition, samples = self.source.get(time, self.num_samples)\n",
    "        fft_blocks = numpy.fft.fft(samples[:self.num_samples].reshape((self.num_blocks, self.num_block_samples)), axis=1)\n",
    "        indices = (numpy.floor(self.t * signal.code.rate) % len(signal.code.sequence)).astype(int)\n",
    "        code_samples = 1. - 2. * signal.code.sequence[indices]\n",
    "        for i, f_dopp in enumerate(self.dopp_bins):\n",
    "            reference = code_samples * numpy.exp(2j * numpy.pi * (self.source.f_center + f_dopp) * self.t)\n",
    "            conjugate_fft = numpy.conj(numpy.fft.fft(reference))\n",
    "            self.correlation[i, :] = numpy.sum(numpy.fft.ifft(conjugate_fft * fft_blocks), axis=0) / self.num_blocks\n",
    "        # perform search\n",
    "        nsc = int(len(signal.code.sequence) * self.source.f_samp / signal.code.rate)  # number of samples in one code period\n",
    "        abs_corr = numpy.absolute(self.correlation[:, :nsc])\n",
    "        f_dopp_i, n0 = numpy.unravel_index(abs_corr.argmax(), abs_corr.shape)\n",
    "        max_val = abs_corr[f_dopp_i, n0]\n",
    "        self.snr = 10 * numpy.log(max_val / ((numpy.sum(abs_corr) - max_val) / (abs_corr.size - 1)))\n",
    "        self.f_dopp = self.dopp_bins[f_dopp_i]\n",
    "        # chip calculation from sample phase n0: chip = \n",
    "        self.chip = (1. - n0 / nsc) * len(signal.code.sequence)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should test our acquisition process on each satellite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gnss.acquisition import coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000.0, 840, 18.753531670966382)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_acquirer = coarse.CoarseAcquirer(source, 10e-3, 3)\n",
    "samples = source.block(coarse_acquirer.num_samples)\n",
    "coarse_acquirer.acquire(signal, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "AquisitionResult = collections.namedtuple(\"AquisitionResult\", \"fd n0 snr\")\n",
    "coarse_aquisition_results = {}\n",
    "print('          PRN\\tdoppler (Hz)\\tsample phase\\t    SNR     ')\n",
    "for sv_id in range(1, 33):\n",
    "    code = gnss_codes.gps_l1_ca(sv_id)\n",
    "    fd_c, n0, snr = aquire_coarse(signal, l_blk, n_blks, fs, fi, fc, code, f_chip)\n",
    "    coarse_aquisition_results[sv_id] = AquisitionResult(fd_c, n0, snr)\n",
    "    print('{0:12}\\t{1:12}\\t{2:12}\\t{3:3.8f}'.format(sv_id, int(fd_c), n0, snr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have good coarse aquisition results for each PRN in the signal. we can pickle our list to a file for later reuse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "results_filepath = '../data/_coarse_aquisition_results.pk'\n",
    "pickle.dump(coarse_aquisition_results, open(results_filepath, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find a the first databit transition by scanning 20ms for flips in correlation values.\n",
    "\n",
    "steps:\n",
    "\n",
    "- wipe off code and coarse doppler using coarse aquisition results for 20ms period\n",
    "- try inserting a data bit transition in each appropriate spot, then see if summation goes up or down\n",
    "\n",
    "After our aquisition stage, we use `fd_c` and `code_phase` to generate the conjugate of a reference signal, which we then use to wipe off code and doppler. We then integrate millisecond by millisecond and check for sign changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sv_id = 21\n",
    "fd_c, n0, snr = coarse_aquisition_results[sv_id]\n",
    "code = gnss_codes.gps_l1_ca(sv_id)\n",
    "l_blk = 5e-3\n",
    "num_blks = 21\n",
    "num_blk_samples = l_blk * fs\n",
    "num_samples = num_blks * num_blk_samples\n",
    "t = np.arange(num_blk_samples * num_blks) / fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to correlate starting at the beginning of a code period--i.e. `n0 = (len(code) - code_phase) / fd_chip * fs` offset from start of `signal` (where `fd_chip = f_chip * (1. + fd_c / fc)`)--so that we can see the difference between correlation periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fd_chip = f_chip * (1. + fd_c / fc)\n",
    "indices = (np.floor(t * fd_chip) % len(code)).astype(int)\n",
    "conj_ref = (1 - 2 * code[indices]) * np.exp(-2j * np.pi * (fi + fd_c) * t)\n",
    "clean_signal = signal[n0:n0 + num_samples] * conj_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(np.absolute(corr), c='r')\n",
    "ax.plot(np.real(corr), c='g')\n",
    "ax.plot(np.imag(corr), c='b')\n",
    "ax.plot((np.real(corr) + np.imag(corr)) / 2., c=(1., .2, 1.))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see the real/imag sign change at the 15th block for PRN 21 (or the first block for PRN 23). One method of detecting the bit edges would be to search for large magnitude changes in one of the correlation components. This will probably only work for signal with strong SNR. (Looking at other PRNs, the data bit transition is either non-existent, or not as clear. We will need to explor other methods for detecing their navigation data phase offsets.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decimate = 2\n",
    "corr_1 = np.sum(clean_signal[:-num_blk_samples].reshape(num_blks / decimate, num_blk_samples * decimate), axis=1)\n",
    "corr_2 = np.sum(clean_signal[num_blk_samples:].reshape(num_blks / decimate, num_blk_samples * decimate), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(np.absolute(corr_1), c='r')\n",
    "ax.plot(np.real(corr_1), c='g')\n",
    "ax.plot(np.imag(corr_1), c='b')\n",
    "ax.plot((np.real(corr_1) + np.imag(corr_1)) / 2., c=(1., .2, 1.))\n",
    "ax = fig.add_subplot(122)\n",
    "ax.plot(np.absolute(corr_2), c='r')\n",
    "ax.plot(np.real(corr_2), c='g')\n",
    "ax.plot(np.imag(corr_2), c='b')\n",
    "ax.plot((np.real(corr_2) + np.imag(corr_2)) / 2., c=(1., .2, 1.))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can encapsulate this process into a function `find_nav_bit_transition`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_nav_bit_transition(signal, fs, fi, fc, fd_c, code, f_chip, tau_c, l_blk=1e-3, num_blks=21):\n",
    "    \"\"\"\n",
    "    signal: ndarray(shape=(ns,), dtype=complex)\n",
    "        the complex intermediate signal\n",
    "    fs: float\n",
    "        sampling frequency\n",
    "    fi: float\n",
    "        intermediate frequency\n",
    "    fc: float\n",
    "        transmitted carrier frequency\n",
    "    fd_c: float\n",
    "        coarse doppler frequency (within +- 1/l_blk Hz)\n",
    "    code: ndarray(shape=(nc,), dtype=int)\n",
    "        the CDMA code to search for in the baseband signal\n",
    "    f_chip: float\n",
    "        the chipping frequency\n",
    "    tau_c: float\n",
    "        time from start of file to beginning of first full code period\n",
    "    l_blk: float\n",
    "        length of on aquisition block for coherent integration in seconds\n",
    "    num_blks: int\n",
    "        number of blocks to scan over\n",
    "        \n",
    "    returns\n",
    "    -------\n",
    "    tau_nav: float\n",
    "        time from start of signal to first detected nav bit transition\n",
    "        returns None if no transition detected.\n",
    "    \"\"\"\n",
    "    n0 = round(tau_c * fs)\n",
    "    num_blk_samples = l_blk * fs\n",
    "    num_samples = num_blks * num_blk_samples\n",
    "    t = np.arange(num_samples) / fs\n",
    "    fd_chip = f_chip * (1 + fd_c / fc)\n",
    "    indices = (np.floor(t * fd_chip) % len(code)).astype(int)\n",
    "    conj_ref = (1 - 2 * code[indices]) * np.exp(-2j * np.pi * (fi + fd_c) * t)\n",
    "    clean_signal = signal[n0:n0 + num_samples] * conj_ref\n",
    "    decimate = 2\n",
    "    corr_1 = np.abs(np.sum(clean_signal[:-num_blk_samples].reshape(num_blks / decimate, num_blk_samples * decimate), axis=1))\n",
    "    corr_2 = np.abs(np.sum(clean_signal[num_blk_samples:].reshape(num_blks / decimate, num_blk_samples * decimate), axis=1))\n",
    "    corr_1 = np.abs(corr_1 - np.mean(corr_1))\n",
    "    corr_2 = np.abs(corr_2 - np.mean(corr_2))\n",
    "    min1_i = corr_1.argmax()\n",
    "    snr1 = 10 * np.log(corr_1[min1_i] / ((np.sum(corr_1) - corr_1[min1_i]) / (corr_1.size - 1)))\n",
    "    min2_i = corr_2.argmin()\n",
    "    snr2 = 10 * np.log(corr_2[min2_i] / ((np.sum(corr_2) - corr_2[min2_i]) / (corr_2.size - 1)))\n",
    "    min_i, snr = (2 * min1_i + 1, snr1) if snr1 > snr2 else (2 * (min2_i + 1) - 1, snr2)\n",
    "    code_period = len(code) / fd_chip\n",
    "    #code_phase_nav = min_i * len(code) + code_phase(min_i * code_period + chip_c / f_chip) * f_chip\n",
    "    tau_nav = min_i * code_period + tau_c\n",
    "    return tau_nav, snr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the algorithm by performing a 40ms integration starting from the beginning of the signal and starting from the `code_phase_nav` offset. (NOTE: Since right now we only have one doppler estimate while performing acquisition, we should just use this coarse doppler to calculate `fd_chip`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0011494014281926176, 17.06572605066421)\n"
     ]
    }
   ],
   "source": [
    "sv_id = 23\n",
    "fd_c, n0, snr = coarse_aquisition_results[sv_id]\n",
    "code = gnss_codes.gps_l1_ca(sv_id)\n",
    "tau_nav, snr = find_nav_bit_transition(signal, fs, fi, fc, fd_c, code, f_chip, n0 / fs)\n",
    "print(tau_nav, snr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a rough estimate, we get SNR values > 14dB for signals with a high enough snr to detect nav transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_blk = 20e-3\n",
    "num_blk_samples = l_blk * fs\n",
    "t = np.arange(num_blk_samples) / fs\n",
    "fd_chip = f_chip * (1 + fd_c / fc)\n",
    "indices = (np.floor(t * fd_chip) % len(code)).astype(int)\n",
    "conj_ref = (1 - 2 * code[indices]) * np.exp(-2j * np.pi * (fi + fd_c) * t)\n",
    "clean_signal_1 = signal[n0:n0 + ns] * conj_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n0 = tau_nav * fs\n",
    "indices = (np.floor(t * fd_chip) % len(code)).astype(int)\n",
    "conj_ref = (1 - 2 * code[indices]) * np.exp(-2j * np.pi * (fi + fd_c) * t)\n",
    "clean_signal_2 = signal[n0:n0 + ns] * conj_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr1 = np.abs(np.sum(clean_signal_1))\n",
    "corr2 = np.abs(np.sum(clean_signal_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation from start of code period: 132956.82995\n",
      "correlation from start of nav period: 146333.867399\n"
     ]
    }
   ],
   "source": [
    "print('correlation from start of code period: {0}\\ncorrelation from start of nav period: {1}'.format(corr1, corr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for PRN 21/23 has a higher correlation when starting from the nav bit transition."
   ]
  }
 ],
 "metadata": {
  "css": [
   ""
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
